{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ac3a06cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آزمایش 1\n",
      "امتیاز Jaccard بر روی داده‌های آموزش: 0.2\n",
      "امتیاز Jaccard بر روی داده‌های تست: 0.2\n",
      "\n",
      "آزمایش 2\n",
      "امتیاز Jaccard بر روی داده‌های آموزش: 0.2\n",
      "امتیاز Jaccard بر روی داده‌های تست: 0.2\n",
      "\n",
      "آزمایش 3\n",
      "امتیاز Jaccard بر روی داده‌های آموزش: 0.16836078981189392\n",
      "امتیاز Jaccard بر روی داده‌های تست: 0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "def som_clustering(data, som_dim, num_iterations, learning_rate, sigma=None, learning_rate_decay=False, decay_start_iteration=0):\n",
    "    input_dim = data.shape[1]\n",
    "    output_dim = (som_dim, som_dim)\n",
    "    \n",
    "    weights = np.random.random((output_dim[0], output_dim[1], input_dim))\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        # Select a random input vector\n",
    "        input_vector = data[np.random.choice(len(data))]\n",
    "        \n",
    "        # Find the best matching unit (BMU)\n",
    "        distances = np.sum((input_vector - weights) ** 2, axis=(1, 2))\n",
    "        bmu_index = np.unravel_index(np.argmin(distances), output_dim)\n",
    "        \n",
    "        # Update the weights of the BMU and its neighbors\n",
    "        for i in range(output_dim[0]):\n",
    "            for j in range(output_dim[1]):\n",
    "                distance_to_bmu = np.sqrt((i - bmu_index[0]) ** 2 + (j - bmu_index[1]) ** 2)\n",
    "                if sigma is None or distance_to_bmu <= sigma:\n",
    "                    if learning_rate_decay and iteration >= decay_start_iteration:\n",
    "                        current_learning_rate = learning_rate / (iteration - decay_start_iteration + 1)\n",
    "                    else:\n",
    "                        current_learning_rate = learning_rate\n",
    "                    weights[i, j] += current_learning_rate * (input_vector - weights[i, j])\n",
    "    \n",
    "    # Assign each data point to its closest cluster\n",
    "    cluster_labels = np.zeros(len(data))\n",
    "    for i, input_vector in enumerate(data):\n",
    "        distances = np.sum((input_vector - weights) ** 2, axis=(1, 2))\n",
    "        bmu_index = np.unravel_index(np.argmin(distances), output_dim)\n",
    "        cluster_labels[i] = bmu_index[0] * som_dim + bmu_index[1]\n",
    "    \n",
    "    return cluster_labels\n",
    "\n",
    "# بارگیری داده‌های CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# تصاویر مربوط به خوشه‌های airplane، cat و bird\n",
    "selected_classes = [0, 3, 2]\n",
    "selected_train_idx = np.isin(y_train, selected_classes).flatten()\n",
    "selected_test_idx = np.isin(y_test, selected_classes).flatten()\n",
    "\n",
    "x_train_selected = x_train[selected_train_idx]\n",
    "y_train_selected = y_train[selected_train_idx]\n",
    "\n",
    "x_test_selected = x_test[selected_test_idx]\n",
    "y_test_selected = y_test[selected_test_idx]\n",
    "\n",
    "# تبدیل تصاویر به بردارهای یک بعدی\n",
    "x_train_selected = x_train_selected.reshape((len(x_train_selected), -1))\n",
    "x_test_selected = x_test_selected.reshape((len(x_test_selected), -1))\n",
    "\n",
    "# مقیاس‌بندی داده‌ها\n",
    "scaler = MinMaxScaler()\n",
    "x_train_selected = scaler.fit_transform(x_train_selected)\n",
    "x_test_selected = scaler.transform(x_test_selected)\n",
    "\n",
    "# پارامترهای آزمایش\n",
    "som_dim = 10\n",
    "num_iterations = 10000\n",
    "\n",
    "# ---------------\n",
    "# آزمایش 1: بدون تعریف همسایگی برای نورون‌های لایه خروجی SOM\n",
    "learning_rate_1 = 0.5\n",
    "\n",
    "train_clusters_1 = som_clustering(x_train_selected, som_dim, num_iterations, learning_rate_1)\n",
    "test_clusters_1 = som_clustering(x_test_selected, som_dim, num_iterations, learning_rate_1)\n",
    "\n",
    "jaccard_train_1 = jaccard_score(y_train_selected, train_clusters_1, average='micro')\n",
    "jaccard_test_1 = jaccard_score(y_test_selected, test_clusters_1, average='micro')\n",
    "\n",
    "print(\"آزمایش 1\")\n",
    "print(\"امتیاز Jaccard بر روی داده‌های آموزش:\", jaccard_train_1)\n",
    "print(\"امتیاز Jaccard بر روی داده‌های تست:\", jaccard_test_1)\n",
    "print()\n",
    "\n",
    "# ---------------\n",
    "# آزمایش 2: بدون تعریف همسایگی برای نورون‌های لایه خروجی SOM با کاهش نرخ یادگیری بعد از تعدادی تکرار SOM\n",
    "learning_rate_2 = 0.5\n",
    "learning_rate_decay_2 = True\n",
    "decay_start_iteration_2 = 5000\n",
    "\n",
    "train_clusters_2 = som_clustering(x_train_selected, som_dim, num_iterations, learning_rate_2,\n",
    "                                  learning_rate_decay=learning_rate_decay_2, decay_start_iteration=decay_start_iteration_2)\n",
    "test_clusters_2 = som_clustering(x_test_selected, som_dim, num_iterations, learning_rate_2,\n",
    "                                 learning_rate_decay=learning_rate_decay_2, decay_start_iteration=decay_start_iteration_2)\n",
    "\n",
    "jaccard_train_2 = jaccard_score(y_train_selected, train_clusters_2, average='micro')\n",
    "jaccard_test_2 = jaccard_score(y_test_selected, test_clusters_2, average='micro')\n",
    "\n",
    "print(\"آزمایش 2\")\n",
    "print(\"امتیاز Jaccard بر روی داده‌های آموزش:\", jaccard_train_2)\n",
    "print(\"امتیاز Jaccard بر روی داده‌های تست:\", jaccard_test_2)\n",
    "print()\n",
    "\n",
    "# ---------------\n",
    "# آزمایش 3: با تعریف همسایگی دلخواه برای نورون‌های لایه خروجی SOM با کاهش نرخ یادگیری بعد از تعدادی تکرار SOM\n",
    "learning_rate_3 = 0.5\n",
    "learning_rate_decay_3 = True\n",
    "decay_start_iteration_3 = 5000\n",
    "sigma_3 = 2\n",
    "\n",
    "train_clusters_3 = som_clustering(x_train_selected, som_dim, num_iterations, learning_rate_3,\n",
    "                                  sigma=sigma_3, learning_rate_decay=learning_rate_decay_3, \n",
    "                                  decay_start_iteration=decay_start_iteration_3)\n",
    "test_clusters_3 = som_clustering(x_test_selected, som_dim, num_iterations, learning_rate_3,\n",
    "                                 sigma=sigma_3, learning_rate_decay=learning_rate_decay_3, \n",
    "                                 decay_start_iteration=decay_start_iteration_3)\n",
    "\n",
    "jaccard_train_3 = jaccard_score(y_train_selected, train_clusters_3, average='micro')\n",
    "jaccard_test_3 = jaccard_score(y_test_selected, test_clusters_3, average='micro')\n",
    "\n",
    "print(\"آزمایش 3\")\n",
    "print(\"امتیاز Jaccard بر روی داده‌های آموزش:\", jaccard_train_3)\n",
    "print(\"امتیاز Jaccard بر روی داده‌های تست:\", jaccard_test_3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18e73bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آزمایش 4\n",
      "امتیاز Jaccard بر روی داده‌های آموزش: 0.2\n",
      "امتیاز Jaccard بر روی داده‌های تست: 0.21040952188823886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "def som_clustering(data, som_dim, num_iterations, learning_rate, sigma=None, learning_rate_decay=False, decay_start_iteration=0, use_labels=False, attraction_factor=0.5):\n",
    "    input_dim = data.shape[1]\n",
    "    output_dim = (som_dim, som_dim)\n",
    "    \n",
    "    weights = np.random.random((output_dim[0], output_dim[1], input_dim))\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        input_vector = data[np.random.choice(len(data))]\n",
    "        \n",
    "        \n",
    "        distances = np.sum((input_vector - weights) ** 2, axis=(1, 2))\n",
    "        bmu_index = np.unravel_index(np.argmin(distances), output_dim)\n",
    "        \n",
    "        \n",
    "        for i in range(output_dim[0]):\n",
    "            for j in range(output_dim[1]):\n",
    "                distance_to_bmu = np.sqrt((i - bmu_index[0]) ** 2 + (j - bmu_index[1]) ** 2)\n",
    "                if sigma is None or distance_to_bmu <= sigma:\n",
    "                    if learning_rate_decay and iteration >= decay_start_iteration:\n",
    "                        current_learning_rate = learning_rate / (iteration - decay_start_iteration + 1)\n",
    "                    else:\n",
    "                        current_learning_rate = learning_rate\n",
    "                    if use_labels:\n",
    "                        label_distance = np.abs(input_vector - weights[i, j])\n",
    "                        weight_update = current_learning_rate * (input_vector - weights[i, j])\n",
    "                        weights[i, j] += weight_update * (1 - attraction_factor * np.mean(label_distance))\n",
    "                    else:\n",
    "                        weights[i, j] += current_learning_rate * (input_vector - weights[i, j])\n",
    "    \n",
    "    \n",
    "    cluster_labels = np.zeros(len(data))\n",
    "    for i, input_vector in enumerate(data):\n",
    "        distances = np.sum((input_vector - weights) ** 2, axis=(1, 2))\n",
    "        bmu_index = np.unravel_index(np.argmin(distances), output_dim)\n",
    "        cluster_labels[i] = bmu_index[0] * som_dim + bmu_index[1]\n",
    "    \n",
    "    return cluster_labels\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "selected_classes = [0, 3, 2]\n",
    "selected_train_idx = np.isin(y_train, selected_classes).flatten()\n",
    "selected_test_idx = np.isin(y_test, selected_classes).flatten()\n",
    "\n",
    "x_train_selected = x_train[selected_train_idx]\n",
    "y_train_selected = y_train[selected_train_idx]\n",
    "\n",
    "x_test_selected = x_test[selected_test_idx]\n",
    "y_test_selected = y_test[selected_test_idx]\n",
    "\n",
    "\n",
    "x_train_selected = x_train_selected.reshape((len(x_train_selected), -1))\n",
    "x_test_selected = x_test_selected.reshape((len(x_test_selected), -1))\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train_selected = scaler.fit_transform(x_train_selected)\n",
    "x_test_selected = scaler.transform(x_test_selected)\n",
    "\n",
    "# پارامترهای آزمایش\n",
    "som_dim = 10\n",
    "num_iterations = 1000\n",
    "\n",
    "\n",
    "learning_rate_4 = 0.3\n",
    "learning_rate_decay_4 = True\n",
    "decay_start_iteration_4 = 5000\n",
    "sigma_4 = 2\n",
    "use_labels_4 = True\n",
    "attraction_factor_4 = 0.5\n",
    "\n",
    "train_clusters_4 = som_clustering(x_train_selected, som_dim, num_iterations, learning_rate_4,\n",
    "                                  sigma=sigma_4, learning_rate_decay=learning_rate_decay_4, \n",
    "                                  decay_start_iteration=decay_start_iteration_4, use_labels=use_labels_4,\n",
    "                                  attraction_factor=attraction_factor_4)\n",
    "test_clusters_4 = som_clustering(x_test_selected, som_dim, num_iterations, learning_rate_4,\n",
    "                                 sigma=sigma_4, learning_rate_decay=learning_rate_decay_4, \n",
    "                                 decay_start_iteration=decay_start_iteration_4, use_labels=use_labels_4,\n",
    "                                 attraction_factor=attraction_factor_4)\n",
    "\n",
    "jaccard_train_4 = jaccard_score(y_train_selected, train_clusters_4, average='micro')\n",
    "jaccard_test_4 = jaccard_score(y_test_selected, test_clusters_4, average='micro')\n",
    "\n",
    "print(\"آزمایش 4\")\n",
    "print(\"امتیاز Jaccard بر روی داده‌های آموزش:\", jaccard_train_4)\n",
    "print(\"امتیاز Jaccard بر روی داده‌های تست:\", jaccard_test_4)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94b26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
